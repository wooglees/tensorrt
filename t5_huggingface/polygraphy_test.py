#!/usr/bin/env python3
# Template auto-generated by polygraphy [v0.43.1] on 04/13/23 at 06:15:24
# Generation Command: /usr/local/bin/polygraphy run models/t5-base-encoder.onnx --trt --onnxrt --fp16 --gen-script polygraphy_test
# This script compares /workspace/naver/TensorRT/demo/HuggingFace/models/t5-base-encoder.onnx between TensorRT and ONNX-Runtime.
import numpy as np
from polygraphy import mod
from polygraphy.logger import G_LOGGER
from polygraphy.backend.onnxrt import OnnxrtRunner, SessionFromOnnx
from polygraphy.backend.trt import CreateConfig as CreateTrtConfig, EngineFromNetwork, NetworkFromOnnxPath, Profile, TrtRunner, EngineFromBytes
from polygraphy.backend.trt import network_from_onnx_path
from polygraphy.backend.common import BytesFromPath
from polygraphy.comparator import Comparator
from polygraphy.exception import PolygraphyException
from utils.trt_utils import add_extra_fp32
from transformers import AutoTokenizer

trt = mod.lazy_import('tensorrt')
G_LOGGER.module_severity = {'': G_LOGGER.VERBOSE}
G_LOGGER.log_file = 'polygraphy_test.log'
ENCODER_ONNX_PATH = 'models/t5-base/ONNX/t5-base-encoder.onnx'
DECODER_ONNX_PATH = 'models/t5-base/ONNX/t5-base-fp16-decoder.onnx'
ENCODER_TRT_PATH = "models/t5-base/TRT/t5-base-trt-encoder.engine"
DECODER_TRT_PATH =  "models/t5-base/TRT/t5-base-trt-fp16-decoder.engine"

tokenizer_path = "t5-base"
tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)
input_text = "premise: If I fall asleep then I am going to wake up in 8 hours. hypothesis: I fell asleep but did not wake up in 8 hours.\n"
batch_size = 1
input = tokenizer([input_text] * batch_size,
                  padding='longest',
                  max_length=512,
                  pad_to_multiple_of=8,
                  truncation=True,
                  return_tensors='pt')
input_ids = input.input_ids.numpy()
attention_mask = input.attention_mask.numpy()
dec_input_ids = np.array([[1]], dtype=np.int32)

############################################### ENCODER ############################################### 
## Loaders
parse_network_from_onnx = NetworkFromOnnxPath(ENCODER_ONNX_PATH)
profiles = [
    Profile().add('input_ids', min=[1, 1], opt=[1, 384], max=[1, 768]).add('attention_mask', min=[1, 1], opt=[1, 384], max=[1, 768])
]
create_trt_config = CreateTrtConfig(fp16=False, profiles=profiles)
build_engine = EngineFromNetwork(parse_network_from_onnx, config=create_trt_config)
build_onnxrt_session = SessionFromOnnx(ENCODER_ONNX_PATH)

## Sample Data
onnx_sample_data = {
    'input_ids':input_ids.astype(np.int64),
    'attention_mask':attention_mask.astype(np.int64)
}

trt_sample_data = {
    'input_ids':input_ids.astype(np.int32),
    'attention_mask':attention_mask.astype(np.int32)
}

## Runners
enc_runners = [
    OnnxrtRunner(build_onnxrt_session),
    TrtRunner(build_engine),
]

with enc_runners[0] as onnx_runner:
    onnx_enc_outputs = onnx_runner.infer(feed_dict=onnx_sample_data)
print("[ ENCODER ONNX outputs ]")
print(onnx_enc_outputs)

with enc_runners[1] as trt_runner:
    trt_enc_outputs = trt_runner.infer(feed_dict=trt_sample_data)
print("[ ENCODER TRT outputs ]")
print(trt_enc_outputs)

print("[ Value comparison ]")
# Value comparison
results = Comparator.run(runners = enc_runners, data_loader = [trt_sample_data])

# Accuracy Comparison
success = True
success &= bool(Comparator.compare_accuracy(results))

# Report Results
if not success:
    raise PolygraphyException('ENCODER FAILED')

############################################### DECODER ############################################### 
## Loaders
parse_decoder_network_from_onnx = add_extra_fp32(network_from_onnx_path(DECODER_ONNX_PATH))
# parse_decoder_network_from_onnx = NetworkFromOnnxPath('./models/t5-base/ONNX/t5-base-decoder.onnx')

decoder_profiles = [
    Profile().add('input_ids', min=[1, 1], opt=[1, 384], max=[1, 768]).add('encoder_hidden_states', min=[1,1,768], opt=[1,384,768], max=[1,768,768]).add('encoder_attention_mask', min=[1, 1], opt=[1, 384], max=[1, 768])
]
build_decoder_onnxrt_session = SessionFromOnnx(DECODER_ONNX_PATH)

if DECODER_TRT_PATH: # Load from existing TRT engine directly.
    load_decoder_engine_bytes = BytesFromPath(DECODER_TRT_PATH)
    decoder_engine = EngineFromBytes(load_decoder_engine_bytes)
else: # Or build it from the ONNX
    create_decoder_trt_config = CreateTrtConfig(tf32=True,
                                                fp16=True, 
                                                profiles=decoder_profiles, 
                                                preview_features=[trt.PreviewFeature.FASTER_DYNAMIC_SHAPES_0805], 
                                                memory_pool_limits={trt.MemoryPoolType.WORKSPACE: 2048 * 1024 * 1024},
                                                precision_constraints="obey")
    decoder_engine = EngineFromNetwork(parse_decoder_network_from_onnx, config=create_decoder_trt_config)

## Sample Data
decoder_onnx_sample_data = {
    'encoder_hidden_states': onnx_enc_outputs['hidden_states'],
    'encoder_attention_mask':attention_mask.astype(np.int64),
    'input_ids':dec_input_ids.astype(np.int64)
}

decoder_trt_sample_data = {
    'encoder_hidden_states':trt_enc_outputs['hidden_states'],
    'encoder_attention_mask':attention_mask.astype(np.int32),
    'input_ids':dec_input_ids.astype(np.int32),
}

# Runners
dec_runners = [
    OnnxrtRunner(build_decoder_onnxrt_session),
    TrtRunner(decoder_engine),
]

with dec_runners[0] as decoder_onnx_runner:
    decoder_onnx_outputs = decoder_onnx_runner.infer(feed_dict=decoder_onnx_sample_data)
print("[ DECODER ONNX outputs ]")
print(decoder_onnx_outputs)

with dec_runners[1] as decoder_trt_runner:
    decoder_trt_outputs = decoder_trt_runner.infer(feed_dict=decoder_trt_sample_data)
print("[ DECODER TRT outputs ]")
print(decoder_trt_outputs)

print("[ Value comparison ]")
# Value comparison
results = Comparator.run(runners = dec_runners, data_loader = [decoder_trt_sample_data])

# Accuracy Comparison
success = True
success &= bool(Comparator.compare_accuracy(results))

# Report Results
if not success:
    raise PolygraphyException('DECODER FAILED')






# trtexec --onnx=T5-base-decoder-with-lm-head.onnx --minShapes=input_ids:1x1,encoder_hidden_states:1x1x768,encoder_attention_mask:1x1,hidden_states:1x1x768 --optShapes=input_ids:1x384,encoder_hidden_states:1x384x768,encoder_attention_mask:1x384,hidden_states:1x32x768 --maxShapes=input_ids:1x768,encoder_hidden_states:1x768x768,encoder_attention_mask:1x768,hidden_states:1x64x768 --saveEngine=removed_decoder.engine
# trtexec --fp16 --outputIOFormat=fp16 --onnx=t5-base-encoder.onnx --minShapes=input_ids:1x1,attention_mask:1x1 --optShapes=input_ids:1x40,attention_mask:1x40 --maxShapes=input_ids:1x64,attention_mask:1x64 --saveEngine=encoder_test.engine
# polygraphy run T5-base-decoder-with-lm-head.onnx --input-shapes input_ids:[1,1] encoder_hidden_states:[1,40,768] encoder_attention_mask:[1,40] --trt-min-shapes input_ids:[1,1] encoder_hidden_states:[1,1,768] encoder_attention_mask:[1,1] --trt-opt-shapes input_ids:[1,384] encoder_hidden_states:[1,384,768] encoder_attention_mask:[1,384] --trt-max-shape input_ids:[1,768] encoder_hidden_states:[1,768,768] encoder_attention_mask:[1,768] --trt
# polygraphy run t5-base-encoder.onnx --input-shapes input_ids:[1,40] attention_mask:[1,40] --trt-min-shapes input_ids:[1,1] attention_mask:[1,1] --trt-opt-shapes input_ids:[1,384] attention_mask:[1,384] --trt-max-shape input_ids:[1,768] attention_mask:[1,768] --trt

